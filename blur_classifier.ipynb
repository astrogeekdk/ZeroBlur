{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFp8ZAAv-VTQ",
        "outputId": "f4554056-4373-4234-da07-bf4dd5253f66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/dikshaadke/motionblurdataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.87G/3.87G [00:42<00:00, 98.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/dikshaadke/motionblurdataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"dikshaadke/motionblurdataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import kagglehub\n",
        "\n",
        "# Download Kaggle dataset\n",
        "path = kagglehub.dataset_download(\"dikshaadke/motionblurdataset\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Set paths\n",
        "base_dir = \"/root/.cache/kagglehub/datasets/dikshaadke/motionblurdataset/versions/1/content/clean_dataset\"\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# Debug: Print directory structure\n",
        "print(\"\\nDataset structure:\")\n",
        "print(\"Base dir contents:\", os.listdir(base_dir))\n",
        "if os.path.exists(train_dir):\n",
        "    print(\"Train dir contents:\", os.listdir(train_dir))\n",
        "else:\n",
        "    print(\"Train dir does not exist:\", train_dir)\n",
        "if os.path.exists(test_dir):\n",
        "    print(\"Test dir contents:\", os.listdir(test_dir))\n",
        "else:\n",
        "    print(\"Test dir does not exist:\", test_dir)\n",
        "\n",
        "# Image parameters\n",
        "IMG_HEIGHT = 128\n",
        "IMG_WIDTH = 128\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "# Custom preprocessing function to handle varying image sizes\n",
        "def preprocess_image(image):\n",
        "    # Convert tensor to PIL Image\n",
        "    image = tf.keras.preprocessing.image.array_to_img(image)\n",
        "\n",
        "    # Resize while preserving aspect ratio\n",
        "    image = image.resize((IMG_WIDTH, IMG_HEIGHT), Image.LANCZOS)\n",
        "\n",
        "    # Convert back to array and normalize\n",
        "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    image = image / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "    return image\n",
        "\n",
        "# Load and preprocess dataset\n",
        "def load_dataset():\n",
        "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_image,\n",
        "        validation_split=0.0  # No validation split since test folder is separate\n",
        "    )\n",
        "\n",
        "    train_generator = datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        classes=['blur', 'non-blur']  # Updated class names\n",
        "    )\n",
        "\n",
        "    test_generator = datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        classes=['blur', 'non-blur']  # Updated class names\n",
        "    )\n",
        "\n",
        "    return train_generator, test_generator\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdIke3N6--qX",
        "outputId": "fa980666-2697-4ac3-c834-9b2129459888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/dikshaadke/motionblurdataset/versions/1\n",
            "\n",
            "Dataset structure:\n",
            "Base dir contents: ['train', 'test']\n",
            "Train dir contents: ['non-blur', 'blur']\n",
            "Test dir contents: ['non-blur', 'blur']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Build deeper CNN model\n",
        "def build_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "        layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2),\n",
        "        layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2),\n",
        "        layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2),\n",
        "        layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "def train_model():\n",
        "    train_generator, test_generator = load_dataset()\n",
        "\n",
        "    model = build_model()\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=test_generator,\n",
        "        epochs=50,\n",
        "        steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "        validation_steps=test_generator.samples // BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Convert to TFLite\n",
        "def convert_to_tflite(model):\n",
        "    # Save the model\n",
        "    model.save('blur_classifier.h5')\n",
        "\n",
        "    # Convert to TFLite with quantization\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    converter.target_spec.supported_types = [tf.float16]  # Reduce model size\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    # Save TFLite model\n",
        "    with open('blur_classifier.tflite', 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "    print(\"TFLite model saved as 'blur_classifier.tflite'\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    model = train_model()\n",
        "    convert_to_tflite(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ktkllm94BUET",
        "outputId": "151c8999-5562-43e3-9f90-d3b1a66d1e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 31649 images belonging to 2 classes.\n",
            "Found 1667 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_35 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_40          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_36 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m2,320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_41          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_20 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_37 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_42          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_38 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_43          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_21 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_39 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_44          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_40 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_45          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_22 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_41 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_46          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_23 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m2,097,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_47          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_40          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_41          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_42          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_43          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_44          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_45          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_46          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_47          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,278,801\u001b[0m (8.69 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,278,801</span> (8.69 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,277,585\u001b[0m (8.69 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,277,585</span> (8.69 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,216\u001b[0m (4.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> (4.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 185ms/step - accuracy: 0.8777 - loss: 0.3313 - val_accuracy: 0.8876 - val_loss: 0.2691\n",
            "Epoch 2/50\n",
            "\u001b[1m  1/989\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 40ms/step - accuracy: 0.9062 - loss: 0.1740"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - accuracy: 0.9062 - loss: 0.1740 - val_accuracy: 0.8876 - val_loss: 0.2722\n",
            "Epoch 3/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 160ms/step - accuracy: 0.9398 - loss: 0.1827 - val_accuracy: 0.9405 - val_loss: 0.1680\n",
            "Epoch 4/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9375 - loss: 0.0999 - val_accuracy: 0.9411 - val_loss: 0.1662\n",
            "Epoch 5/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 167ms/step - accuracy: 0.9440 - loss: 0.1604 - val_accuracy: 0.9177 - val_loss: 0.2166\n",
            "Epoch 6/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0442 - val_accuracy: 0.9207 - val_loss: 0.2092\n",
            "Epoch 7/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 154ms/step - accuracy: 0.9518 - loss: 0.1422 - val_accuracy: 0.9303 - val_loss: 0.2235\n",
            "Epoch 8/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9375 - loss: 0.1502 - val_accuracy: 0.9207 - val_loss: 0.2369\n",
            "Epoch 9/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 161ms/step - accuracy: 0.9531 - loss: 0.1365 - val_accuracy: 0.9261 - val_loss: 0.2426\n",
            "Epoch 10/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0471 - val_accuracy: 0.9243 - val_loss: 0.2458\n",
            "Epoch 11/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 153ms/step - accuracy: 0.9566 - loss: 0.1242 - val_accuracy: 0.9423 - val_loss: 0.1385\n",
            "Epoch 12/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9062 - loss: 0.3830 - val_accuracy: 0.9513 - val_loss: 0.1313\n",
            "Epoch 13/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 204ms/step - accuracy: 0.9599 - loss: 0.1133 - val_accuracy: 0.9483 - val_loss: 0.1608\n",
            "Epoch 14/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0169 - val_accuracy: 0.9531 - val_loss: 0.1526\n",
            "Epoch 15/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 211ms/step - accuracy: 0.9581 - loss: 0.1120 - val_accuracy: 0.9411 - val_loss: 0.1615\n",
            "Epoch 16/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0546 - val_accuracy: 0.9393 - val_loss: 0.1634\n",
            "Epoch 17/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 157ms/step - accuracy: 0.9648 - loss: 0.0991 - val_accuracy: 0.9736 - val_loss: 0.0916\n",
            "Epoch 18/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9062 - loss: 0.2889 - val_accuracy: 0.9748 - val_loss: 0.0885\n",
            "Epoch 19/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 164ms/step - accuracy: 0.9656 - loss: 0.0966 - val_accuracy: 0.8582 - val_loss: 0.2970\n",
            "Epoch 20/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9375 - loss: 0.0968 - val_accuracy: 0.8425 - val_loss: 0.3116\n",
            "Epoch 21/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 172ms/step - accuracy: 0.9688 - loss: 0.0873 - val_accuracy: 0.8576 - val_loss: 0.2926\n",
            "Epoch 22/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9688 - loss: 0.1356 - val_accuracy: 0.8438 - val_loss: 0.3212\n",
            "Epoch 23/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 203ms/step - accuracy: 0.9707 - loss: 0.0812 - val_accuracy: 0.9724 - val_loss: 0.0815\n",
            "Epoch 24/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 0.9724 - val_loss: 0.0803\n",
            "Epoch 25/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 204ms/step - accuracy: 0.9768 - loss: 0.0610 - val_accuracy: 0.9766 - val_loss: 0.0791\n",
            "Epoch 26/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9375 - loss: 0.1307 - val_accuracy: 0.9772 - val_loss: 0.0794\n",
            "Epoch 27/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 152ms/step - accuracy: 0.9746 - loss: 0.0697 - val_accuracy: 0.9501 - val_loss: 0.1371\n",
            "Epoch 28/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9688 - loss: 0.1666 - val_accuracy: 0.9525 - val_loss: 0.1299\n",
            "Epoch 29/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 153ms/step - accuracy: 0.9790 - loss: 0.0600 - val_accuracy: 0.9784 - val_loss: 0.0887\n",
            "Epoch 30/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9688 - loss: 0.0726 - val_accuracy: 0.9784 - val_loss: 0.0873\n",
            "Epoch 31/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 155ms/step - accuracy: 0.9797 - loss: 0.0551 - val_accuracy: 0.9627 - val_loss: 0.1028\n",
            "Epoch 32/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.9657 - val_loss: 0.1018\n",
            "Epoch 33/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 162ms/step - accuracy: 0.9843 - loss: 0.0449 - val_accuracy: 0.9724 - val_loss: 0.1140\n",
            "Epoch 34/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9375 - loss: 0.1360 - val_accuracy: 0.9724 - val_loss: 0.1078\n",
            "Epoch 35/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 204ms/step - accuracy: 0.9848 - loss: 0.0410 - val_accuracy: 0.8942 - val_loss: 0.4154\n",
            "Epoch 36/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0272 - val_accuracy: 0.8972 - val_loss: 0.3985\n",
            "Epoch 37/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 204ms/step - accuracy: 0.9806 - loss: 0.0545 - val_accuracy: 0.9459 - val_loss: 0.1828\n",
            "Epoch 38/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9423 - val_loss: 0.1894\n",
            "Epoch 39/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 205ms/step - accuracy: 0.9856 - loss: 0.0395 - val_accuracy: 0.9766 - val_loss: 0.1178\n",
            "Epoch 40/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9688 - loss: 0.0735 - val_accuracy: 0.9766 - val_loss: 0.1172\n",
            "Epoch 41/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 152ms/step - accuracy: 0.9862 - loss: 0.0416 - val_accuracy: 0.9724 - val_loss: 0.1747\n",
            "Epoch 42/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.9736 - val_loss: 0.1752\n",
            "Epoch 43/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 152ms/step - accuracy: 0.9885 - loss: 0.0310 - val_accuracy: 0.9754 - val_loss: 0.1760\n",
            "Epoch 44/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9754 - val_loss: 0.1714\n",
            "Epoch 45/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 153ms/step - accuracy: 0.9888 - loss: 0.0324 - val_accuracy: 0.9736 - val_loss: 0.0990\n",
            "Epoch 46/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9688 - loss: 0.0421 - val_accuracy: 0.9760 - val_loss: 0.0977\n",
            "Epoch 47/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 204ms/step - accuracy: 0.9893 - loss: 0.0296 - val_accuracy: 0.9688 - val_loss: 0.1395\n",
            "Epoch 48/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0300 - val_accuracy: 0.9669 - val_loss: 0.1501\n",
            "Epoch 49/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 152ms/step - accuracy: 0.9900 - loss: 0.0304 - val_accuracy: 0.9802 - val_loss: 0.1306\n",
            "Epoch 50/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 9.4612e-04 - val_accuracy: 0.9802 - val_loss: 0.1303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpbsgety22'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='keras_tensor_130')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  138640418715216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640418716752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640418717328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640418715792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640418714448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640418716560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640418715024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419128720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419127952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419127568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419127760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419128528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419130448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419131024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419131216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419130064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419128144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419130832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419132752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419133328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419133520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419132368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419128912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419133136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419135056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419135632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419135824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419134672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419129296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419135440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419137360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419137936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419138128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419136976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419131600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419137744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419139664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419140240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419140432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419139280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419133904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419140048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419141968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419142544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419142736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419143504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419136208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419142352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419140816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640419138512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640452765072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138640452765648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "TFLite model saved as 'blur_classifier.tflite'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_test_dataset():\n",
        "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_image\n",
        "    )\n",
        "    test_generator = datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        classes=['blur', 'non-blur'],\n",
        "        shuffle=False\n",
        "    )\n",
        "    return test_generator\n",
        "\n",
        "# Evaluate Keras model\n",
        "def evaluate_keras_model():\n",
        "    model = tf.keras.models.load_model('blur_classifier.h5')\n",
        "    test_generator = load_test_dataset()\n",
        "    loss, accuracy = model.evaluate(test_generator)\n",
        "    print(f\"Keras Model - Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Evaluate TFLite model\n",
        "def evaluate_tflite_model():\n",
        "    test_generator = load_test_dataset()\n",
        "    interpreter = tf.lite.Interpreter(model_path='blur_classifier.tflite')\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_generator:\n",
        "        for i in range(len(images)):\n",
        "            interpreter.set_tensor(input_details[0]['index'], images[i:i+1])\n",
        "            interpreter.invoke()\n",
        "            prediction = interpreter.get_tensor(output_details[0]['index'])\n",
        "            predicted_label = 1 if prediction[0] > 0.5 else 0\n",
        "            if predicted_label == int(labels[i]):\n",
        "                correct += 1\n",
        "            total += 1\n",
        "        if total >= test_generator.samples:\n",
        "            break\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"TFLite Model - Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Evaluating Keras model...\")\n",
        "    evaluate_keras_model()\n",
        "    print(\"\\nEvaluating TFLite model...\")\n",
        "    evaluate_tflite_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioQkXmcxXIfH",
        "outputId": "0cc0eee8-87dc-4b76-9cee-6bb33e4080e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Keras model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1667 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 145ms/step - accuracy: 0.9768 - loss: 0.1503\n",
            "Keras Model - Test Loss: 0.1300, Test Accuracy: 0.9802\n",
            "\n",
            "Evaluating TFLite model...\n",
            "Found 1667 images belonging to 2 classes.\n",
            "TFLite Model - Test Accuracy: 0.9802\n"
          ]
        }
      ]
    }
  ]
}